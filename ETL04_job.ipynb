{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%help",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 4.0\n%worker_type G.1X\n%number_of_workers 5\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.2 \nCurrent idle_timeout is None minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 4.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nPrevious number of workers: None\nSetting new number of workers to: 5\nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 5\nSession ID: 93b50815-5204-4657-8ad8-2a9fdb36f567\nApplying the following default arguments:\n--glue_kernel_version 1.0.2\n--enable-glue-datacatalog true\nWaiting for session 93b50815-5204-4657-8ad8-2a9fdb36f567 to get into ready status...\nSession 93b50815-5204-4657-8ad8-2a9fdb36f567 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Create a DynamicFrame from a table in the AWS Glue Data Catalog and display its schema\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "dyf = glueContext.create_dynamic_frame.from_catalog(database='proyectoint20232', table_name='file_csv')\ndyf.printSchema()",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n|-- col1: string\n|-- col2: string\n|-- col3: string\n|-- col4: string\n|-- col5: string\n|-- col6: string\n|-- col7: string\n|-- col8: string\n|-- col9: string\n|-- col10: string\n|-- col11: string\n|-- col12: string\n|-- col13: string\n|-- col14: string\n|-- col15: string\n|-- col16: string\n|-- col17: string\n|-- col18: string\n|-- col0: long\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Definir la lista de los nuevos nombres de las columnas\ncolumn_names = [\n    \"serial\", \"mfr\", \"fecha\", \"requested_test_kv\", \"test_kv\", \"ma\", \"watts\",\n    \"measured_cap\", \"pfm\", \"pfm_tipup\", \"line_id\", \"group_number\", \"circuit\",\n    \"location\", \"division\", \"company\", \"cct_designation\", \"stator_kv\"\n]\n\n# Renombrar las columnas en el DynamicFrame\nfor i in range(1, 19):  # Desde col1 hasta col18\n    old_column_name = f\"col{i}\"\n    new_column_name = column_names[i - 1]\n    dyf = dyf.rename_field(old_column_name, new_column_name)\n\n# Verificar el esquema después de renombrar\ndyf.printSchema()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n|-- serial: string\n|-- mfr: string\n|-- fecha: string\n|-- requested_test_kv: string\n|-- test_kv: string\n|-- ma: string\n|-- watts: string\n|-- measured_cap: string\n|-- pfm: string\n|-- pfm_tipup: string\n|-- line_id: string\n|-- group_number: string\n|-- circuit: string\n|-- location: string\n|-- division: string\n|-- company: string\n|-- cct_designation: string\n|-- stator_kv: string\n|-- col0: long\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from awsglue.transforms import *\n\n# Columnas a eliminar\ncolumns_to_drop = [\"line_id\", \"circuit\", \"location\", \"division\", \"company\", \"cct_designation\",\"col0\"]\n\n# Utilizar DropFields para eliminar las columnas\ndyf = DropFields.apply(frame=dyf, paths=columns_to_drop)\n\n# Verificar el esquema después de la eliminación\ndyf.printSchema()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n|-- serial: string\n|-- mfr: string\n|-- fecha: string\n|-- requested_test_kv: string\n|-- test_kv: string\n|-- ma: string\n|-- watts: string\n|-- measured_cap: string\n|-- pfm: string\n|-- pfm_tipup: string\n|-- group_number: string\n|-- stator_kv: string\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Convert the DynamicFrame to a Spark DataFrame and display a sample of the data\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "DF = dyf.toDF()\nDF.show()",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "+------+-------+-------------------+-----------------+------------------+------------------+-------------------+------------------+-------------------+-------------------+------------+---------+\n|serial|    mfr|              fecha|requested_test_kv|           test_kv|                ma|              watts|      measured_cap|                pfm|          pfm_tipup|group_number|stator_kv|\n+------+-------+-------------------+-----------------+------------------+------------------+-------------------+------------------+-------------------+-------------------+------------+---------+\n|serial|    mfr|              fecha|requested_test_kv|           test_kv|                ma|              watts|      measured_cap|                pfm|          pfm_tipup|group_number|stator_kv|\n|715015|Toshiba|2018-11-27 16:07:37|              2.0|1.9947197437286377|3572.8927850723267|  388.1911926269531| 948070.8058617892|  1.086489900421389|                   |           0|     13.8|\n|715015|Toshiba|2018-11-27 16:07:37|              4.0| 4.015733480453491| 3583.967685699463| 458.96038818359375| 950296.2541318992| 1.2805929864125465| 0.1941030859911572|           0|     13.8|\n|715015|Toshiba|2018-11-27 16:07:37|              6.0| 5.990353345870972| 3568.703293800354|  517.6515197753905| 947210.9638863913| 1.4505311233765736| 0.3640412229551846|           0|     13.8|\n|715015|Toshiba|2018-11-27 16:07:37|              8.0| 8.009872913360596| 3599.445462226868|   585.986572265625| 954618.2582198525|  1.627991251472089| 0.5415013510506999|           0|     13.8|\n|715015|Toshiba|2018-11-27 16:07:37|              2.0|2.0006251335144043| 3562.023162841797|  385.1232299804688| 945508.9582388608| 1.0811923796509393|                   |           1|     13.8|\n|715015|Toshiba|2018-11-27 16:07:37|              4.0| 4.013310194015503| 3574.055790901184|  456.2605285644531| 947913.2074829978|  1.276590392701757| 0.1953980130508177|           1|     13.8|\n|715015|Toshiba|2018-11-27 16:07:37|              6.0|  6.00162148475647| 3580.474019050598|  518.1038208007812| 950094.8010554566|  1.447025779391529| 0.3658333997405898|           1|     13.8|\n|715015|Toshiba|2018-11-27 16:07:37|              8.0| 7.991638660430909|   3590.8123254776|  582.5667724609375| 952265.4238480753| 1.6223815662197063|  0.541189186568767|           1|     13.8|\n|715015|Toshiba|2018-11-27 16:07:37|              2.0| 1.994096279144287|3559.4671964645386|  387.1838684082031| 944746.2048228773| 1.0877579340884944|                   |           2|     13.8|\n|715015|Toshiba|2018-11-27 16:07:37|              4.0| 4.011608123779297|3571.8520879745483|  458.4482879638672| 947374.8718846764| 1.2835030025664769| 0.1957450684779822|           2|     13.8|\n|715015|Toshiba|2018-11-27 16:07:37|              6.0| 6.004915952682495| 3578.862190246582|  523.7073974609375| 949380.0519067008| 1.4633349081956528| 0.3755769741071584|           2|     13.8|\n|715015|Toshiba|2018-11-27 16:07:37|              8.0| 7.984984397888183|3591.2749767303467|  589.5313720703125| 951963.8695110189| 1.6415656720529033| 0.5538077379644086|           2|     13.8|\n|715015|Toshiba|2018-11-27 16:07:37|              2.0|1.9999933242797847|21.084900945425037|-1.6540625095367432| 5592.005525301146|-0.7844772492970326|                   |           3|     13.8|\n|715015|Toshiba|2018-11-27 16:07:37|              4.0|3.9938268661499023|21.035843528807163|-2.1405662298202515|  5581.55544005956|-1.0175804107350823|-0.2331031614380497|           3|     13.8|\n|715015|Toshiba|2018-11-27 16:07:37|              6.0| 6.000165939331056|21.014433354139328|-2.5983704328536987| 5572.824868238513|-1.2364694251162778|-0.4519921758192452|           3|     13.8|\n|715015|Toshiba|2018-11-27 16:07:37|              8.0| 8.019349575042723| 20.97716275602579|-3.0464520454406734|5561.1117932841125| -1.452270776974148|-0.6677935276771155|           3|     13.8|\n|715015|Toshiba|2018-11-27 16:07:37|              2.0| 1.993308961391449| 19.25612986087799|-1.6209792494773865|5110.5819576235945|-0.8417990848569595|                   |           4|     13.8|\n|715015|Toshiba|2018-11-27 16:07:37|              4.0| 4.005605459213257|19.225595518946648| -2.116055011749268| 5099.763722427042|-1.1006447158757269|-0.2588456310187671|           4|     13.8|\n|715015|Toshiba|2018-11-27 16:07:37|              6.0| 6.006616353988648| 19.19594127684832| -2.595219135284424| 5089.015431281041|-1.3519624267732286|-0.5101633419162691|           4|     13.8|\n+------+-------+-------------------+-----------------+------------------+------------------+-------------------+------------------+-------------------+-------------------+------------+---------+\nonly showing top 20 rows\n\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Convertir el DataFrame de Spark en un DataFrame de pandas\ndf = DF.toPandas()\ndf.info()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17355 entries, 0 to 17354\nData columns (total 12 columns):\n #   Column             Non-Null Count  Dtype \n---  ------             --------------  ----- \n 0   serial             17355 non-null  object\n 1   mfr                17355 non-null  object\n 2   fecha              17355 non-null  object\n 3   requested_test_kv  17355 non-null  object\n 4   test_kv            17355 non-null  object\n 5   ma                 17355 non-null  object\n 6   watts              17355 non-null  object\n 7   measured_cap       17355 non-null  object\n 8   pfm                17355 non-null  object\n 9   pfm_tipup          17355 non-null  object\n 10  group_number       17355 non-null  object\n 11  stator_kv          17355 non-null  object\ndtypes: object(12)\nmemory usage: 1.6+ MB\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Seleccionar columnas de interés para primera parte del proceso\ncolumnas_obj = ['serial', 'fecha' , 'stator_kv','mfr', 'group_number', 'requested_test_kv', 'test_kv', 'ma', 'watts',\n                'measured_cap', 'pfm']\n\n# Crea un nuevo DataFrame con las columnas seleccionadas\ndf = df[columnas_obj].copy()\ndf.info()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17355 entries, 0 to 17354\nData columns (total 11 columns):\n #   Column             Non-Null Count  Dtype \n---  ------             --------------  ----- \n 0   serial             17355 non-null  object\n 1   fecha              17355 non-null  object\n 2   stator_kv          17355 non-null  object\n 3   mfr                17355 non-null  object\n 4   group_number       17355 non-null  object\n 5   requested_test_kv  17355 non-null  object\n 6   test_kv            17355 non-null  object\n 7   ma                 17355 non-null  object\n 8   watts              17355 non-null  object\n 9   measured_cap       17355 non-null  object\n 10  pfm                17355 non-null  object\ndtypes: object(11)\nmemory usage: 1.5+ MB\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "import pandas as pd\n\n# Suponiendo que 'df' es tu DataFrame\n# Seleccionar desde la segunda fila hasta el final\ndf = df.iloc[1:]\n\n# Mostrar el DataFrame resultante\nprint(df)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 11,
			"outputs": [
				{
					"name": "stdout",
					"text": "         serial                fecha  ...       measured_cap                 pfm\n1        715015  2018-11-27 16:07:37  ...  948070.8058617892   1.086489900421389\n2        715015  2018-11-27 16:07:37  ...  950296.2541318992  1.2805929864125465\n3        715015  2018-11-27 16:07:37  ...  947210.9638863913  1.4505311233765736\n4        715015  2018-11-27 16:07:37  ...  954618.2582198525   1.627991251472089\n5        715015  2018-11-27 16:07:37  ...  945508.9582388608  1.0811923796509393\n...         ...                  ...  ...                ...                 ...\n17350  82EU7701  2005-10-01 17:29:11  ...             3318.6                 2.0\n17351  82EU7701  2005-10-01 17:29:11  ...             2988.4                1.97\n17352  82EU7701  2005-10-01 17:29:11  ...             2994.2                 1.9\n17353  82EU7701  2005-10-01 17:29:11  ...             2996.4                1.95\n17354  82EU7701  2005-10-01 17:29:11  ...             2998.4                2.01\n\n[17354 rows x 11 columns]\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df['mfr']",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 12,
			"outputs": [
				{
					"name": "stdout",
					"text": "1        Toshiba\n2        Toshiba\n3        Toshiba\n4        Toshiba\n5        Toshiba\n          ...   \n17350     Alstom\n17351     Alstom\n17352     Alstom\n17353     Alstom\n17354     Alstom\nName: mfr, Length: 17354, dtype: object\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Estandarizar valores de columna group_number\n\n# Reemplazar los valores en la columna group_number\ndf['group_number'] = df['group_number'].replace({'0': 'GST', '1': 'GST', '2': 'GST', '3': 'UST', '4': 'UST', '5': 'UST', '6':'GST'})\n\n#Deteccion de group_number incorrecto\nvalores_grnuin = df['group_number'].unique()\nvalores_grnuin",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 13,
			"outputs": [
				{
					"name": "stdout",
					"text": "array(['GST', 'UST'], dtype=object)\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df['group_number']",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 14,
			"outputs": [
				{
					"name": "stdout",
					"text": "1        GST\n2        GST\n3        GST\n4        GST\n5        GST\n        ... \n17350    UST\n17351    UST\n17352    UST\n17353    UST\n17354    UST\nName: group_number, Length: 17354, dtype: object\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Estandarizacion de columna mfr empleando diccionario\n# Diccionario de mapeo de valores originales a valores deseados\nmapeo = {\n  'Ansal' : 'ANS',\n  'General Electric' : 'GE',\n  'Brown Boveri Company' : 'GMX',\n  'Mitsubishi' : 'MIT',\n  'ENERGOMEX' : 'ENG',\n  'Rade-Koncar' : 'RK',\n  'Toshiba' : 'TOS',\n  'AEG Power Tool Corp.' : 'GMX',\n  'Alstom' : 'ALS',\n  'ASEA' : 'GMX',\n  'RADE KONCAR' : 'RK',\n  'Westinghouse Electric' : 'OTH',\n  'TIBB' : 'GMX',\n  'ABB (ASEA-Brown Boveri)' : 'GMX',\n  'Koch & Sterzel' : 'OTH',\n  'Hitachi' : 'HIT',\n  'ASEA Inc.' : 'GMX',\n  'Cenemesa' : 'OTH',\n  'HITACHI' : 'HIT',\n  'Raychem' : 'OTH',\n  'Brush Ltd. (H-S Group)' : 'OTH',\n  'HARBIN ELECTRIC MACHINERY' : 'OTH',\n  'Magnetek' : 'OTH',\n  'GAMESA' : 'OTH'\n}\n\n# Cambiar los valores en la columna 'mfr' utilizando el diccionario\ndf['mfr'] = df['mfr'].map(mapeo)\ndf['mfr']",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 15,
			"outputs": [
				{
					"name": "stdout",
					"text": "1        TOS\n2        TOS\n3        TOS\n4        TOS\n5        TOS\n        ... \n17350    ALS\n17351    ALS\n17352    ALS\n17353    ALS\n17354    ALS\nName: mfr, Length: 17354, dtype: object\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Contar la cantidad de ceros en la columna\ncantidad_ceros = (df['pfm'] == '0.0').sum()\n\n# Contar la cantidad de NaN en la columna\ncantidad_nan = (df['pfm'] == '').sum()\n\nprint(f\"Cantidad de ceros en {'pfm'}: {cantidad_ceros}\")\nprint(f\"Cantidad de NaN en {'pfm'}: {cantidad_nan}\")\ndf.info()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 16,
			"outputs": [
				{
					"name": "stdout",
					"text": "Cantidad de ceros en pfm: 43\nCantidad de NaN en pfm: 1363\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17354 entries, 1 to 17354\nData columns (total 11 columns):\n #   Column             Non-Null Count  Dtype \n---  ------             --------------  ----- \n 0   serial             17354 non-null  object\n 1   fecha              17354 non-null  object\n 2   stator_kv          17354 non-null  object\n 3   mfr                17354 non-null  object\n 4   group_number       17354 non-null  object\n 5   requested_test_kv  17354 non-null  object\n 6   test_kv            17354 non-null  object\n 7   ma                 17354 non-null  object\n 8   watts              17354 non-null  object\n 9   measured_cap       17354 non-null  object\n 10  pfm                17354 non-null  object\ndtypes: object(11)\nmemory usage: 1.5+ MB\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Eliminar filas con 'pfm'= 0 o NaN\ncolumna_filtrar = 'pfm'\ndf = df[(df[columna_filtrar] != '0.0') & (df[columna_filtrar] != '')]\n\n# Contar la cantidad de ceros en la columna\ncantidad_ceros = (df['pfm'] == '0.0').sum()\n\n# Contar la cantidad de NaN en la columna\ncantidad_nan = (df['pfm'] == '').sum()\n\nprint(f\"Cantidad de ceros en {'pfm'}: {cantidad_ceros}\")\nprint(f\"Cantidad de NaN en {'pfm'}: {cantidad_nan}\")\ndf.info()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 17,
			"outputs": [
				{
					"name": "stdout",
					"text": "Cantidad de ceros en pfm: 0\nCantidad de NaN en pfm: 0\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 15948 entries, 1 to 17354\nData columns (total 11 columns):\n #   Column             Non-Null Count  Dtype \n---  ------             --------------  ----- \n 0   serial             15948 non-null  object\n 1   fecha              15948 non-null  object\n 2   stator_kv          15948 non-null  object\n 3   mfr                15948 non-null  object\n 4   group_number       15948 non-null  object\n 5   requested_test_kv  15948 non-null  object\n 6   test_kv            15948 non-null  object\n 7   ma                 15948 non-null  object\n 8   watts              15948 non-null  object\n 9   measured_cap       15948 non-null  object\n 10  pfm                15948 non-null  object\ndtypes: object(11)\nmemory usage: 1.5+ MB\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df['requested_test_kv']",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 18,
			"outputs": [
				{
					"name": "stdout",
					"text": "1        2.0\n2        4.0\n3        6.0\n4        8.0\n5        2.0\n        ... \n17350    8.0\n17351    2.0\n17352    4.0\n17353    6.0\n17354    8.0\nName: requested_test_kv, Length: 15948, dtype: object\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Estandarizacion de valores no válidos para columna requested_text_kv (rtkv)\n#conservar sólo valores válidos de tension de prueba\n\n# Valores permitidos para la variable \"requested_test_kv\"\nvalidos_tkv = ['1.0','2.0','3.0', '4.0', '6.0', '8.0', '10.0']\n\n# Filtrar el DataFrame para conservar solo las filas con los valores permitidos\ndf = df[df['requested_test_kv'].isin(validos_tkv)]\n\n# Obtener los valores únicos de la columna 'requested_test_kv'\nvalores_rtkv = df['requested_test_kv'].unique()\nvalores_rtkv",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 19,
			"outputs": [
				{
					"name": "stdout",
					"text": "array(['2.0', '4.0', '6.0', '8.0', '1.0', '3.0', '10.0'], dtype=object)\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df.tail()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 20,
			"outputs": [
				{
					"name": "stdout",
					"text": "         serial                fecha stator_kv  ...  watts measured_cap   pfm\n17350  82EU7701  2005-10-01 17:29:11      13.8  ...  2.505       3318.6   2.0\n17351  82EU7701  2005-10-01 17:29:11      13.8  ...  2.216       2988.4  1.97\n17352  82EU7701  2005-10-01 17:29:11      13.8  ...  2.141       2994.2   1.9\n17353  82EU7701  2005-10-01 17:29:11      13.8  ...  2.207       2996.4  1.95\n17354  82EU7701  2005-10-01 17:29:11      13.8  ...  2.274       2998.4  2.01\n\n[5 rows x 11 columns]\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "\n# Suponiendo que 'df' es tu DataFrame\n# Filtrar donde 'pfm' es '0.0', 0, o ''\ndatos_filtrados = df[df['pfm'].isin(['0.0', 0]) | (df['pfm'] == '')]\n\n# Mostrar los datos filtrados\nprint(datos_filtrados)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 21,
			"outputs": [
				{
					"name": "stdout",
					"text": "Empty DataFrame\nColumns: [serial, fecha, stator_kv, mfr, group_number, requested_test_kv, test_kv, ma, watts, measured_cap, pfm]\nIndex: []\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql import SparkSession\nfrom awsglue.dynamicframe import DynamicFrame\n\n# Inicializa la sesión de Spark\nspark = SparkSession.builder.appName(\"pandasToSpark\").getOrCreate()\n\n# Suponiendo que 'pandas_df' es tu DataFrame de pandas\nspark_df = spark.createDataFrame(df)\n\n# Convertir el DataFrame de Spark en un DynamicFrame\nglueContext = GlueContext(spark.sparkContext)\ndyf = DynamicFrame.fromDF(spark_df, glueContext, \"dyf\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 25,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "dyf.printSchema()\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 26,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n|-- serial: string\n|-- fecha: string\n|-- stator_kv: string\n|-- mfr: string\n|-- group_number: string\n|-- requested_test_kv: string\n|-- test_kv: string\n|-- ma: string\n|-- watts: string\n|-- measured_cap: string\n|-- pfm: string\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Suponiendo que 'dyf' es tu DynamicFrame\nnum_registros = dyf.count()\n\n# Imprimir el número de registros\nprint(\"Número de registros en el DynamicFrame:\", num_registros)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 28,
			"outputs": [
				{
					"name": "stdout",
					"text": "Número de registros en el DynamicFrame: 15604\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Ahora puedes usar el dyf con el código para escribir en S3\ns3output_parquet = glueContext.getSink(\n    path=\"s3://proyectointegrador20232/trusted/all_files_E_parquet/\",\n    connection_type=\"s3\",\n    updateBehavior=\"UPDATE_IN_DATABASE\",\n    partitionKeys=[],\n    compression=\"snappy\",\n    enableUpdateCatalog=True,\n    transformation_ctx=\"s3output_parquet\",\n)\ns3output_parquet.setCatalogInfo(\n    catalogDatabase=\"proyectoint20232\", catalogTableName=\"file_csv\",\n)\ns3output_parquet.setFormat(\"glueparquet\")\ns3output_parquet.writeFrame(dyf)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 27,
			"outputs": [
				{
					"name": "stdout",
					"text": "<awsglue.dynamicframe.DynamicFrame object at 0x7f8192d66fb0>\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}