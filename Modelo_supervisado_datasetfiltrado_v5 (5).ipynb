{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydsAdsFSo4qX",
        "outputId": "9e6a1f7c-1eb7-4db8-f875-a6f302aaa4be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Configuro el Google Colab conectandome a los datos desde la cuenta de Google\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "ydsAdsFSo4qX"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fa67805c-3939-40a5-b451-7645a169f613"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import time\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "\n",
        "\n",
        "\n",
        "# Desactivar las advertencias de convergencia para mejorar la legibilidad\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n"
      ],
      "id": "fa67805c-3939-40a5-b451-7645a169f613"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79e5e82f-82d4-4c71-90b7-cf63272e6750"
      },
      "source": [
        "# Preparación de los datos"
      ],
      "id": "79e5e82f-82d4-4c71-90b7-cf63272e6750"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "19qoGz3V0_HT"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv('/content/gdrive/MyDrive/EAFIT/ProyectoIntegrador1/DatasetsRM/csv/df_familias_filtrado.csv') #dataframe etiquetado por k-means\n",
        "df2 = pd.read_csv('/content/gdrive/MyDrive/EAFIT/ProyectoIntegrador1/DatasetsRM/csv/all_files_E(2).csv') #Dataframe original Inicial, empleado en RAW"
      ],
      "id": "19qoGz3V0_HT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14CbW8XBvyWe"
      },
      "source": [
        "# Fusión de dataframes\n",
        "\n",
        "## Split de columnas"
      ],
      "id": "14CbW8XBvyWe"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3GIcIe_wv0yg"
      },
      "outputs": [],
      "source": [
        "#Split de columna familia en columnas categóricas\n",
        "df1['family'] = df1['family'].str.split('_')\n",
        "# Añadir las nuevas columnas al DataFrame original df1\n",
        "df1[['group_number', 'stator_kv', 'mfr', 'requested_test_kv']] = pd.DataFrame(df1['family'].tolist(), index=df1.index) #creación de columnas categorías\n",
        "# Eliminar la columna original si es necesario\n",
        "df1 = df1.drop(columns=['family']) #Se elimina la columna family\n",
        "df1 = df1.drop(columns=['Unnamed: 0'])#Se elimina columna innecesaria\n",
        "#df1.to_csv('D:/Analitica/Modelos/Finales/out/df_family_split.csv') # Dataset etiquetado, con columnas separadas a Trusted\n",
        "#Convertir formato de las columnas\n",
        "columns_to_convert = ['test_kv', 'ma', 'requested_test_kv']\n",
        "df1_clean = df1.copy() # Se trabajará con dataframe limpio, para no modificar el original df1\n",
        "df1_clean[columns_to_convert] = df1_clean[columns_to_convert].astype(float)"
      ],
      "id": "3GIcIe_wv0yg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCA2EGuqwFc8"
      },
      "source": [
        "## Etiquetado del dataframe original"
      ],
      "id": "bCA2EGuqwFc8"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tfiGh3aAwHFU"
      },
      "outputs": [],
      "source": [
        "#Redefinicion de variables; Se volverán a concatenar en 1 sola columna (clave), para mantener un orden lógico de formación\n",
        "df1_1= df1_clean\n",
        "df1_1['clave'] = df1['stator_kv'].astype(str) + '_' + df1['mfr'].astype(str) + '_' + df1['group_number'].astype(str)+ '_' + df1['test_kv'].astype(str)+ '_' + df1['ma'].astype(str)\n",
        "#df1_1.head()"
      ],
      "id": "tfiGh3aAwHFU"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zk9dDmVGwKHW"
      },
      "outputs": [],
      "source": [
        "#Redefinicion de variables; Se volverán a concatenar en 1 sola columna (clave), para mantener un orden lógico de formación\n",
        "df2_2 =df2\n",
        "df2_2 = df2_2.drop(columns=['Unnamed: 0'])\n",
        "df2_2['clave'] = df2_2['stator_kv'].astype(str) + '_' + df2_2['mfr'].astype(str) + '_' + df2['group_number'].astype(str)+ '_' + df2_2['test_kv'].astype(str)+ '_' + df2_2['ma'].astype(str)\n",
        "#df2_2.head(5)"
      ],
      "id": "zk9dDmVGwKHW"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmGFAOqMwNct",
        "outputId": "8b4acd3a-0c69-4f19-8ca4-7c99b0e0cf79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conteo de NaN en df1_1:\n",
            "test_kv              0\n",
            "ma                   0\n",
            "qual                 0\n",
            "group_number         0\n",
            "stator_kv            0\n",
            "mfr                  0\n",
            "requested_test_kv    0\n",
            "clave                0\n",
            "dtype: int64\n",
            "\n",
            "Conteo de NaN en df2_2:\n",
            "serial               0\n",
            "fecha                0\n",
            "stator_kv            0\n",
            "mfr                  0\n",
            "group_number         0\n",
            "requested_test_kv    0\n",
            "test_kv              0\n",
            "ma                   0\n",
            "watts                0\n",
            "measured_cap         2\n",
            "pfm                  0\n",
            "clave                0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Contar NaN en df1_1\n",
        "nan_count_df1_1= df1_1.isna().sum()\n",
        "# Contar NaN en df2_2\n",
        "nan_count_df2_2 = df2_2.isna().sum()\n",
        "print(\"Conteo de NaN en df1_1:\")\n",
        "print(nan_count_df1_1)\n",
        "print(\"\\nConteo de NaN en df2_2:\")\n",
        "print(nan_count_df2_2)"
      ],
      "id": "GmGFAOqMwNct"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ti4iJFa6wP3l",
        "outputId": "d6b082d0-9345-47e2-b09d-d40afb339305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Conteo de NaN en df2:\n",
            "serial               0\n",
            "fecha                0\n",
            "stator_kv            0\n",
            "mfr                  0\n",
            "group_number         0\n",
            "requested_test_kv    0\n",
            "test_kv              0\n",
            "ma                   0\n",
            "watts                0\n",
            "measured_cap         0\n",
            "pfm                  0\n",
            "clave                0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df2_2 = df2_2.dropna()\n",
        "#Contar NaN en df2\n",
        "nan_count_df2_2 = df2_2.isna().sum()\n",
        "print(\"\\nConteo de NaN en df2:\")\n",
        "print(nan_count_df2_2)"
      ],
      "id": "ti4iJFa6wP3l"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zsxdl80RwSV4"
      },
      "outputs": [],
      "source": [
        "#Inicializacion de dataframe con dataset original + eqtiquetas de df2\n",
        "df3 =[]\n",
        "#df3\n",
        "# Fusionar df2 con df1 para obtener las etiquetas de entrenamiento en df3 en la columna 'clave'\n",
        "df3 = pd.merge(df2_2, df1_1[['clave', 'qual']], on='clave', how='left')"
      ],
      "id": "zsxdl80RwSV4"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "M8hKTgPTwW76"
      },
      "outputs": [],
      "source": [
        "# Contar NaN en df3\n",
        "nan_count_df3 = df3.isna().sum()\n",
        "# Eliminar filas con NaN en df3\n",
        "df3 = df3.dropna()"
      ],
      "id": "M8hKTgPTwW76"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78ledIp3wb_C"
      },
      "source": [
        "## Salida de dataframe etiquetado a dataset *.csv"
      ],
      "id": "78ledIp3wb_C"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_4LUTk6siQO",
        "outputId": "d243be04-d7ed-4bf9-bc73-121486c55b41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 55100 entries, 0 to 57544\n",
            "Data columns (total 13 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   serial             55100 non-null  object \n",
            " 1   fecha              55100 non-null  object \n",
            " 2   stator_kv          55100 non-null  float64\n",
            " 3   mfr                55100 non-null  object \n",
            " 4   group_number       55100 non-null  object \n",
            " 5   requested_test_kv  55100 non-null  float64\n",
            " 6   test_kv            55100 non-null  float64\n",
            " 7   ma                 55100 non-null  float64\n",
            " 8   watts              55100 non-null  float64\n",
            " 9   measured_cap       55100 non-null  float64\n",
            " 10  pfm                55100 non-null  float64\n",
            " 11  clave              55100 non-null  object \n",
            " 12  qual               55100 non-null  float64\n",
            "dtypes: float64(8), object(5)\n",
            "memory usage: 5.9+ MB\n"
          ]
        }
      ],
      "source": [
        "df3.info()"
      ],
      "id": "A_4LUTk6siQO"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GE-Rf5xyxoal"
      },
      "outputs": [],
      "source": [
        "# Eliminar las columnas utilizadas en el proceso no supervisado, paso necesario para evitar sesgar el modelo\n",
        "# Dado el planteamiento del problema y que en algunos casos la variable pfm no está disponible, también se excluye del análisis\n",
        "df3_cleaned = df3.drop(['requested_test_kv', 'test_kv', 'ma', 'watts','pfm'], axis=1)"
      ],
      "id": "GE-Rf5xyxoal"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqw5gg2bOa-g",
        "outputId": "6bce6839-31a2-489c-c8c9-db8b46e178e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 55100 entries, 0 to 57544\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   serial        55100 non-null  object \n",
            " 1   fecha         55100 non-null  object \n",
            " 2   stator_kv     55100 non-null  float64\n",
            " 3   mfr           55100 non-null  object \n",
            " 4   group_number  55100 non-null  object \n",
            " 5   measured_cap  55100 non-null  float64\n",
            " 6   clave         55100 non-null  object \n",
            " 7   qual          55100 non-null  float64\n",
            "dtypes: float64(3), object(5)\n",
            "memory usage: 3.8+ MB\n"
          ]
        }
      ],
      "source": [
        "df3_cleaned.info()"
      ],
      "id": "lqw5gg2bOa-g"
    },
    {
      "cell_type": "code",
      "source": [
        "# Suponiendo que 'df3_cleaned' es tu DataFrame\n",
        "df3_cleaned.to_csv('df3_cleaned.csv', index=False)"
      ],
      "metadata": {
        "id": "pZXMccJk2T01"
      },
      "id": "pZXMccJk2T01",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMOs5IaDx7Gk"
      },
      "source": [
        "# Preprocesamiento de Datos para Modelado Supervisado"
      ],
      "id": "EMOs5IaDx7Gk"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "if3xgm6fOTOH",
        "outputId": "f7e0ca96-9ed7-4a4c-face-602d40bf955e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Datos preparados y listos para el modelado.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Seleccionar las variables predictoras (X) y la variable objetivo (y)\n",
        "X = df3_cleaned.drop('qual', axis=1)\n",
        "y = df3_cleaned['qual']\n",
        "\n",
        "# Identificar las características numéricas y categóricas\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Definir transformaciones para las características numéricas\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),  # Imputar valores faltantes usando la mediana\n",
        "    ('scaler', StandardScaler())  # Estandarizar los valores numéricos para que tengan media cero y varianza unitaria\n",
        "])\n",
        "\n",
        "# Definir transformaciones para las características categóricas\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  # Imputar valores faltantes con 'missing'\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Codificar variables categóricas con One-Hot Encoding\n",
        "])\n",
        "\n",
        "# Combinar las transformaciones en un preprocesador usando ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),  # Aplicar transformaciones numéricas\n",
        "        ('cat', categorical_transformer, categorical_features)  # Aplicar transformaciones categóricas\n",
        "])\n",
        "\n",
        "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Imprimir mensaje indicando que los datos están listos para el modelado\n",
        "\"Datos preparados y listos para el modelado.\""
      ],
      "id": "if3xgm6fOTOH"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bJx_CtzYBPGC"
      },
      "outputs": [],
      "source": [
        "# Definir los modelos a utilizar\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Support Vector Machine\": SVC(probability=True),\n",
        "}\n"
      ],
      "id": "bJx_CtzYBPGC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ji-it9Gx_eA"
      },
      "source": [
        "#Función de entrenamiento y evaluación de los modelos\n"
      ],
      "id": "3ji-it9Gx_eA"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z_nwKBNKWW0y"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_model(model_name, X_train, X_test, y_train, y_test):\n",
        "    if model_name not in models:\n",
        "        print(f\"Modelo '{model_name}' no encontrado.\")\n",
        "        return\n",
        "\n",
        "    model = models[model_name]\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                               ('classifier', model)])\n",
        "\n",
        "    # Ajustar el preprocesador y transformar los datos de entrenamiento y prueba\n",
        "    X_train_transformed = pipeline.named_steps['preprocessor'].fit_transform(X_train)\n",
        "    X_test_transformed = pipeline.named_steps['preprocessor'].transform(X_test)\n",
        "\n",
        "    # Entrenar y obtener probabilidades de clase (si está disponible)\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        model.fit(X_train_transformed, y_train)\n",
        "        y_pred_probabilities = model.predict_proba(X_test_transformed)\n",
        "    else:\n",
        "        # Si no hay predict_proba, utilizar predicciones directas\n",
        "        model.fit(X_train_transformed, y_train)\n",
        "        y_pred_probabilities = model.predict(X_test_transformed)\n",
        "\n",
        "    # Predecir las clases\n",
        "    y_pred = model.predict(X_test_transformed)\n",
        "\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    print(f\"Resultados para {model_name}:\\n{report}\\n\")\n",
        "\n",
        "    # Evaluar el modelo utilizando K-fold cross-validation\n",
        "    cv_results = cross_val_score(model, X_train_transformed, y_train, cv=5, scoring='accuracy')\n",
        "    mean_cv_accuracy = np.mean(cv_results)\n",
        "    print(f\"Accuracy promedio en K-fold cross-validation: {mean_cv_accuracy}\\n\")\n",
        "\n",
        "    return y_pred, X_test_transformed, report, mean_cv_accuracy"
      ],
      "id": "Z_nwKBNKWW0y"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1TXJjxuyEna"
      },
      "source": [
        "#Función para graficar la curva ROC en un modelo Multiclase"
      ],
      "id": "R1TXJjxuyEna"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KTod0LHuWiTZ"
      },
      "outputs": [],
      "source": [
        "def plot_roc_curve_multiclass_from_probabilities(y_true, y_pred_probabilities):\n",
        "    # Convertir las etiquetas a su representación numérica\n",
        "    y_true_numeric = label_binarize(y_true, classes=np.unique(y_true))\n",
        "\n",
        "    # Inicializar el diccionario para almacenar las tasas de falsos positivos y verdaderos positivos\n",
        "    fpr_dict = {}\n",
        "    tpr_dict = {}\n",
        "    auc_dict = {}\n",
        "\n",
        "    # Obtener el número de clases\n",
        "    n_classes = y_true_numeric.shape[1]\n",
        "\n",
        "    # Calcular las tasas de falsos positivos y verdaderos positivos para cada clase\n",
        "    for i in range(n_classes):\n",
        "        fpr_dict[i], tpr_dict[i], _ = roc_curve(y_true_numeric[:, i], y_pred_probabilities[:, i])\n",
        "        auc_dict[i] = auc(fpr_dict[i], tpr_dict[i])\n",
        "\n",
        "    # Calcular el micro promedio de ROC-AUC\n",
        "    fpr_micro, tpr_micro, _ = roc_curve(y_true_numeric.ravel(), y_pred_probabilities.ravel())\n",
        "    auc_micro = auc(fpr_micro, tpr_micro)\n",
        "\n",
        "    # Calcular el macro promedio de ROC-AUC\n",
        "    all_fpr = np.unique(np.concatenate([fpr_dict[i] for i in range(n_classes)]))\n",
        "    mean_tpr = np.zeros_like(all_fpr)\n",
        "    for i in range(n_classes):\n",
        "        mean_tpr += np.interp(all_fpr, fpr_dict[i], tpr_dict[i])\n",
        "    mean_tpr /= n_classes\n",
        "    fpr_macro = all_fpr\n",
        "    tpr_macro = mean_tpr\n",
        "    auc_macro = auc(fpr_macro, tpr_macro)\n",
        "\n",
        "    # Plotear la curva ROC para cada clase\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(fpr_micro, tpr_micro, label=f'Micro-average ROC curve (AUC = {auc_micro:.2f})', color='deeppink', linestyle=':', linewidth=4)\n",
        "    plt.plot(fpr_macro, tpr_macro, label=f'Macro-average ROC curve (AUC = {auc_macro:.2f})', color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        plt.plot(fpr_dict[i], tpr_dict[i], label=f'Class {i} (AUC = {auc_dict[i]:.2f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', linewidth=2)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve for Multiclass Classification')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ],
      "id": "KTod0LHuWiTZ"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymP96KfCat8_",
        "outputId": "0c702200-8476-4363-fdc6-6269a8cdca3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados para Support Vector Machine:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.88      0.91      3158\n",
            "         1.0       0.94      0.94      0.94      5024\n",
            "         2.0       0.91      0.97      0.94      4624\n",
            "         3.0       0.97      0.94      0.95      3724\n",
            "\n",
            "    accuracy                           0.94     16530\n",
            "   macro avg       0.94      0.93      0.93     16530\n",
            "weighted avg       0.94      0.94      0.94     16530\n",
            "\n",
            "\n",
            "Accuracy promedio en K-fold cross-validation: 0.883795696136894\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_name = \"Support Vector Machine\"  # Evaluación del modelo SVM\n",
        "model = models[model_name]\n",
        "y_pred, X_test_transformed, report, cv_results = train_and_evaluate_model(model_name, X_train, X_test, y_train, y_test)"
      ],
      "id": "ymP96KfCat8_"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKSXbHXqTdDz",
        "outputId": "e05dd67d-f4fb-4517-9d14-61df601ed1a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados para K-Nearest Neighbors:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.82      0.83      3158\n",
            "         1.0       0.87      0.89      0.88      5024\n",
            "         2.0       0.89      0.88      0.89      4624\n",
            "         3.0       0.91      0.89      0.90      3724\n",
            "\n",
            "    accuracy                           0.87     16530\n",
            "   macro avg       0.87      0.87      0.87     16530\n",
            "weighted avg       0.87      0.87      0.87     16530\n",
            "\n",
            "\n",
            "Accuracy promedio en K-fold cross-validation: 0.8483536427275084\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_name = \"K-Nearest Neighbors\"  # Evaluación del modelo Knn\n",
        "model = models[model_name]\n",
        "y_pred, X_test_transformed, report, cv_results = train_and_evaluate_model(model_name, X_train, X_test, y_train, y_test)"
      ],
      "id": "uKSXbHXqTdDz"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}